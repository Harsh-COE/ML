{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgqZtz/Fyd/aP/5qLHl+E1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsh-COE/ML/blob/main/Assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wikeeijJHrWA",
        "outputId": "edfa668d-5b56-410e-9ed0-d488b629e531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           x         y        x_2         x_3         x_4          x_5  \\\n",
            "0   1.047198  1.065763   1.096623    1.148381    1.202581     1.259340   \n",
            "1   1.117011  1.006086   1.247713    1.393709    1.556788     1.738948   \n",
            "2   1.186824  0.695374   1.408551    1.671702    1.984016     2.354677   \n",
            "3   1.256637  0.949799   1.579137    1.984402    2.493673     3.133642   \n",
            "4   1.326450  1.063496   1.759470    2.333850    3.095735     4.106339   \n",
            "5   1.396263  0.876795   1.949551    2.722087    3.800751     5.306850   \n",
            "6   1.466077  1.034349   2.149381    3.151156    4.619837     6.773034   \n",
            "7   1.535890  1.015673   2.358957    3.623098    5.564680     8.546734   \n",
            "8   1.605703  1.000035   2.578282    4.139955    6.647537    10.673970   \n",
            "9   1.675516  0.968332   2.807354    4.703767    7.881237    13.205140   \n",
            "10  1.745329  1.049762   3.046174    5.316577    9.279177    16.195219   \n",
            "11  1.815142  1.150751   3.294742    5.980426   10.855325    19.703961   \n",
            "12  1.884956  0.806297   3.553058    6.697356   12.624218    23.796091   \n",
            "13  1.954769  1.081425   3.821121    7.469408   14.600965    28.541510   \n",
            "14  2.024582  0.933089   4.098932    8.298624   16.801244    34.015494   \n",
            "15  2.094395  0.932796   4.386491    9.187045   19.241302    40.298889   \n",
            "16  2.164208  0.658547   4.683797   10.136713   21.937959    47.478311   \n",
            "17  2.234021  0.808281   4.990852   11.149670   24.908602    55.646350   \n",
            "18  2.303835  0.965825   5.307654   12.227957   28.171190    64.901763   \n",
            "19  2.373648  0.532688   5.634204   13.373615   31.744252    75.349674   \n",
            "20  2.443461  0.346128   5.970501   14.588687   35.646887    87.101777   \n",
            "21  2.513274  0.326279   6.316547   15.875214   39.898764   100.276530   \n",
            "22  2.583087  0.569830   6.672340   17.235237   44.520121   114.999358   \n",
            "23  2.652900  0.827217   7.037881   18.670797   49.531767   131.402848   \n",
            "24  2.722714  0.575290   7.413170   20.183938   54.955082   149.626952   \n",
            "25  2.792527  0.592913   7.798206   21.776699   60.812016   169.819185   \n",
            "26  2.862340  0.290510   8.192990   23.451123   67.125087   192.134820   \n",
            "27  2.932153  0.417611   8.597522   25.209251   73.917386   216.737094   \n",
            "28  3.001966  0.098486   9.011802   27.053125   81.212571   243.797402   \n",
            "29  3.071779  0.161737   9.435829   28.984787   89.034873   273.495495   \n",
            "30  3.141593 -0.040098   9.869604   31.006277   97.409091   306.019685   \n",
            "31  3.211406 -0.152153  10.313127   33.119637  106.360596   341.567038   \n",
            "32  3.281219 -0.119267  10.766398   35.326910  115.915328   380.343575   \n",
            "33  3.351032 -0.279333  11.229417   37.630136  126.099796   422.564473   \n",
            "34  3.420845 -0.079366  11.702183   40.031357  136.941082   468.454262   \n",
            "35  3.490659 -0.312768  12.184697   42.532615  148.466836   518.247023   \n",
            "36  3.560472 -0.346705  12.676959   45.135952  160.705278   572.186590   \n",
            "37  3.630285 -0.520116  13.178968   47.843408  173.685199   630.526745   \n",
            "38  3.700098 -0.341448  13.690725   50.657026  187.435960   693.531422   \n",
            "39  3.769911 -0.697581  14.212230   53.578846  201.987491   761.474902   \n",
            "40  3.839724 -0.543753  14.743483   56.610911  217.370294   834.642013   \n",
            "41  3.909538 -0.747289  15.284484   59.755262  233.615441   913.328331   \n",
            "42  3.979351 -0.884060  15.835232   63.013941  250.754571   997.840376   \n",
            "43  4.049164 -0.861411  16.395728   66.388989  268.819897  1088.495812   \n",
            "44  4.118977 -0.949726  16.965972   69.882448  287.844200  1185.623647   \n",
            "45  4.188790 -0.897930  17.545963   73.496360  307.860831  1289.564433   \n",
            "46  4.258603 -0.949665  18.135703   77.232765  328.903713  1400.670460   \n",
            "47  4.328417 -0.880358  18.735190   81.093705  351.007336  1519.305962   \n",
            "48  4.398230 -0.866284  19.344425   85.081223  374.206764  1645.847309   \n",
            "49  4.468043 -0.992409  19.963407   89.197360  398.537628  1780.683213   \n",
            "50  4.537856 -0.988694  20.592138   93.444156  424.036130  1924.214920   \n",
            "51  4.607669 -0.951158  21.230616   97.823655  450.739043  2076.856415   \n",
            "52  4.677482 -1.080373  21.878842  102.337896  478.683708  2239.034617   \n",
            "53  4.747296 -0.893167  22.536815  106.988923  507.908039  2411.189580   \n",
            "54  4.817109 -0.868188  23.204537  111.778776  538.450517  2593.774691   \n",
            "55  4.886922 -0.954271  23.882006  116.709497  570.350197  2787.256871   \n",
            "56  4.956735 -0.611090  24.569223  121.783127  603.646700  2992.116770   \n",
            "57  5.026548 -0.813438  25.266187  127.001709  638.380219  3208.848970   \n",
            "58  5.096361 -0.944025  25.972900  132.367284  674.591518  3437.962183   \n",
            "59  5.166175 -0.953121  26.689360  137.881893  712.321929  3679.979448   \n",
            "\n",
            "             x_6           x_7            x_8           x_9          x_10  \\\n",
            "0       1.318778      1.381021       1.446202  1.514459e+00  1.585938e+00   \n",
            "1       1.942424      2.169709       2.423588  2.707173e+00  3.023942e+00   \n",
            "2       2.794587      3.316683       3.936319  4.671717e+00  5.544505e+00   \n",
            "3       3.937850      4.948448       6.218404  7.814277e+00  9.819710e+00   \n",
            "4       5.446854      7.224981       9.583578  1.271214e+01  1.686202e+01   \n",
            "5       7.409760     10.345976      14.445708  2.017001e+01  2.816265e+01   \n",
            "6       9.929787     14.557828      21.342890  3.129031e+01  4.587399e+01   \n",
            "7      13.126841     20.161381      30.965658  4.755984e+01  7.304667e+01   \n",
            "8      17.139225     27.520503      44.189752  7.095561e+01  1.139336e+02   \n",
            "9      22.125424     37.071504      62.113901  1.040728e+02  1.743757e+02   \n",
            "10     28.265990     49.333460      86.103130  1.502783e+02  2.622851e+02   \n",
            "11     35.765495     64.919467     117.838079  2.138929e+02  3.882461e+02   \n",
            "12     44.854574     84.548881     159.370885  3.004070e+02  5.662539e+02   \n",
            "13     55.792053    109.060562     213.188180  4.167336e+02  8.146178e+02   \n",
            "14     68.867155    139.427197     282.281785  5.715026e+02  1.157054e+03   \n",
            "15     84.401795    176.770706     370.227700  7.754031e+02  1.624000e+03   \n",
            "16    102.752954    222.378793     481.274024  1.041577e+03  2.254190e+03   \n",
            "17    124.315140    277.722688     620.438441  1.386073e+03  3.096516e+03   \n",
            "18    149.522928    344.476097     793.615955  1.828360e+03  4.212239e+03   \n",
            "19    178.853587    424.535421    1007.697562  2.391919e+03  5.677573e+03   \n",
            "20    212.829792    520.041285    1270.700574  3.104907e+03  7.586720e+03   \n",
            "21    252.022409    633.401398    1591.911344  4.000910e+03  1.005538e+04   \n",
            "22    297.053380    767.314810    1982.041137  5.119785e+03  1.322485e+04   \n",
            "23    348.598676    924.797589    2453.395952  6.508615e+03  1.726671e+04   \n",
            "24    407.391343   1109.209963    3020.061087  8.222761e+03  2.238822e+04   \n",
            "25    474.224625   1324.284975    3698.101288  1.032705e+04  2.883856e+04   \n",
            "26    549.955176   1574.158684    4505.777325  1.289707e+04  3.691579e+04   \n",
            "27    635.506352   1863.401948    5463.779880  1.602064e+04  4.697497e+04   \n",
            "28    731.871587   2197.053849    6595.481644  1.979941e+04  5.943717e+04   \n",
            "29    840.117850   2580.656776    7927.208539  2.435064e+04  7.479979e+04   \n",
            "30    961.389194   3020.293228    9488.531016  2.980910e+04  9.364805e+04   \n",
            "31   1096.910373   3522.624361   11312.576388  3.632927e+04  1.166680e+05   \n",
            "32   1247.990562   4094.930337   13436.363201  4.408765e+04  1.446612e+05   \n",
            "33   1416.027142   4745.152497   15901.158638  5.328529e+04  1.785607e+05   \n",
            "34   1602.509577   5481.937409   18752.860008  6.415063e+04  2.194494e+05   \n",
            "35   1809.023379   6314.682842   22042.401362  7.694250e+04  2.685800e+05   \n",
            "36   2037.254145   7253.585676   25826.186336  9.195340e+04  3.273975e+05   \n",
            "37   2288.991686   8309.691827   30166.548301  1.095132e+05  3.975640e+05   \n",
            "38   2566.134238   9494.948197   35132.238969  1.299927e+05  4.809858e+05   \n",
            "39   2870.692750  10822.256704   40798.946588  1.538084e+05  5.798440e+05   \n",
            "40   3204.795266  12305.530435   47249.844905  1.814264e+05  6.966273e+05   \n",
            "41   3570.691384  13959.751952   54576.174090  2.133676e+05  8.341686e+05   \n",
            "42   3970.756793  15801.033802   62877.854835  2.502130e+05  9.956854e+05   \n",
            "43   4407.497909  17846.681265   72264.136881  2.926093e+05  1.184823e+06   \n",
            "44   4883.556576  20115.257383   82854.283209  3.412749e+05  1.405703e+06   \n",
            "45   5401.714865  22626.650317   94778.291216  3.970064e+05  1.662976e+06   \n",
            "46   5964.899950  25402.143057  108177.652151  4.606857e+05  1.961878e+06   \n",
            "47   6576.189063  28464.485542  123206.150163  5.332875e+05  2.308291e+06   \n",
            "48   7238.814543  31837.969225  140030.702310  6.158872e+05  2.708813e+06   \n",
            "49   7956.168961  35548.504117  158832.240898  7.096693e+05  3.170833e+06   \n",
            "50   8731.810327  39623.698366  179806.639557  8.159366e+05  3.702603e+06   \n",
            "51   9569.467389  44092.940389  203165.684482  9.361203e+05  4.313333e+06   \n",
            "52  10473.045003  48987.483628  229138.092260  1.071789e+06  5.013276e+06   \n",
            "53  11446.629600  54340.533937  257970.575782  1.224663e+06  5.813835e+06   \n",
            "54  12494.494722  60187.339672  289928.959703  1.396619e+06  6.727667e+06   \n",
            "55  13621.106657  66565.284502  325299.346982  1.589713e+06  7.768801e+06   \n",
            "56  14831.130142  73513.982988  364389.338029  1.806181e+06  8.952763e+06   \n",
            "57  16129.434161  81075.378985  407529.304011  2.048466e+06  1.029671e+07   \n",
            "58  17521.097818  89293.846882  455073.715919  2.319220e+06  1.181958e+07   \n",
            "59  19011.416302  98216.295741  507402.530978  2.621330e+06  1.354225e+07   \n",
            "\n",
            "            x_11          x_12          x_13          x_14          x_15  \n",
            "0   1.660790e+00  1.739176e+00  1.821260e+00  1.907219e+00  1.997235e+00  \n",
            "1   3.377775e+00  3.773011e+00  4.214494e+00  4.707635e+00  5.258479e+00  \n",
            "2   6.580351e+00  7.809718e+00  9.268760e+00  1.100039e+01  1.305552e+01  \n",
            "3   1.233981e+01  1.550666e+01  1.948625e+01  2.448714e+01  3.077145e+01  \n",
            "4   2.236663e+01  2.966822e+01  3.935342e+01  5.220035e+01  6.924117e+01  \n",
            "5   3.932248e+01  5.490454e+01  7.666120e+01  1.070392e+02  1.494550e+02  \n",
            "6   6.725479e+01  9.860066e+01  1.445561e+02  2.119303e+02  3.107061e+02  \n",
            "7   1.121916e+02  1.723140e+02  2.646553e+02  4.064813e+02  6.243104e+02  \n",
            "8   1.829436e+02  2.937530e+02  4.716801e+02  7.573781e+02  1.216124e+03  \n",
            "9   2.921693e+02  4.895344e+02  8.202227e+02  1.374296e+03  2.302656e+03  \n",
            "10  4.577739e+02  7.989662e+02  1.394459e+03  2.433790e+03  4.247765e+03  \n",
            "11  7.047219e+02  1.279171e+03  2.321877e+03  4.214537e+03  7.649985e+03  \n",
            "12  1.067364e+03  2.011933e+03  3.792404e+03  7.148513e+03  1.347463e+04  \n",
            "13  1.592389e+03  3.112753e+03  6.084713e+03  1.189421e+04  2.325042e+04  \n",
            "14  2.342550e+03  4.742685e+03  9.601954e+03  1.943994e+04  3.935776e+04  \n",
            "15  3.401299e+03  7.123663e+03  1.491976e+04  3.124788e+04  6.544541e+04  \n",
            "16  4.878537e+03  1.055817e+04  2.285008e+04  4.945233e+04  1.070251e+05  \n",
            "17  6.917684e+03  1.545425e+04  3.452513e+04  7.712989e+04  1.723098e+05  \n",
            "18  9.704302e+03  2.235711e+04  5.150707e+04  1.186638e+05  2.733817e+05  \n",
            "19  1.347656e+04  3.198861e+04  7.592968e+04  1.802303e+05  4.278033e+05  \n",
            "20  1.853785e+04  4.529652e+04  1.106803e+05  2.704429e+05  6.608168e+05  \n",
            "21  2.527193e+04  6.351529e+04  1.596313e+05  4.011973e+05  1.008319e+06  \n",
            "22  3.416095e+04  8.824071e+04  2.279335e+05  5.887720e+05  1.520850e+06  \n",
            "23  4.580686e+04  1.215210e+05  3.223832e+05  8.552506e+05  2.268895e+06  \n",
            "24  6.095672e+04  1.659677e+05  4.518825e+05  1.230347e+06  3.349882e+06  \n",
            "25  8.053244e+04  2.248890e+05  6.280085e+05  1.753731e+06  4.897340e+06  \n",
            "26  1.056655e+05  3.024507e+05  8.657167e+05  2.477976e+06  7.092809e+06  \n",
            "27  1.377378e+05  4.038683e+05  1.184204e+06  3.472267e+06  1.018122e+07  \n",
            "28  1.784284e+05  5.356360e+05  1.607961e+06  4.827046e+06  1.449063e+07  \n",
            "29  2.297684e+05  7.057980e+05  2.168056e+06  6.659789e+06  2.045740e+07  \n",
            "30  2.942040e+05  9.242692e+05  2.903677e+06  9.122171e+06  2.865815e+07  \n",
            "31  3.746684e+05  1.203212e+06  3.864003e+06  1.240888e+07  3.984996e+07  \n",
            "32  4.746652e+05  1.557480e+06  5.110434e+06  1.676845e+07  5.502097e+07  \n",
            "33  5.983628e+05  2.005133e+06  6.719265e+06  2.251647e+07  7.545342e+07  \n",
            "34  7.507024e+05  2.568037e+06  8.784857e+06  3.005164e+07  1.028020e+08  \n",
            "35  9.375210e+05  3.272566e+06  1.142341e+07  3.987522e+07  1.391908e+08  \n",
            "36  1.165690e+06  4.150404e+06  1.477740e+07  5.261451e+07  1.873325e+08  \n",
            "37  1.443270e+06  5.239483e+06  1.902082e+07  6.905098e+07  2.506747e+08  \n",
            "38  1.779695e+06  6.585045e+06  2.436531e+07  9.015404e+07  3.335788e+08  \n",
            "39  2.185960e+06  8.240877e+06  3.106737e+07  1.171212e+08  4.415367e+08  \n",
            "40  2.674857e+06  1.027071e+07  3.943671e+07  1.514261e+08  5.814344e+08  \n",
            "41  3.261214e+06  1.274984e+07  4.984597e+07  1.948747e+08  7.618699e+08  \n",
            "42  3.962181e+06  1.576691e+07  6.274206e+07  2.496727e+08  9.935351e+08  \n",
            "43  4.797543e+06  1.942604e+07  7.865921e+07  3.185040e+08  1.289675e+09  \n",
            "44  5.790060e+06  2.384912e+07  9.823400e+07  4.046236e+08  1.666635e+09  \n",
            "45  6.965859e+06  2.917852e+07  1.222227e+08  5.119653e+08  2.144515e+09  \n",
            "46  8.354859e+06  3.558003e+07  1.515212e+08  6.452689e+08  2.747944e+09  \n",
            "47  9.991243e+06  4.324626e+07  1.871878e+08  8.102269e+08  3.507000e+09  \n",
            "48  1.191398e+07  5.240044e+07  2.304692e+08  1.013656e+09  4.458293e+09  \n",
            "49  1.416742e+07  6.330062e+07  2.828299e+08  1.263696e+09  5.646249e+09  \n",
            "50  1.680188e+07  7.624451e+07  3.459866e+08  1.570037e+09  7.124604e+09  \n",
            "51  1.987441e+07  9.157471e+07  4.219460e+08  1.944187e+09  8.958172e+09  \n",
            "52  2.344951e+07  1.096847e+08  5.130481e+08  2.399774e+09  1.122490e+10  \n",
            "53  2.759999e+07  1.310253e+08  6.220160e+08  2.952894e+09  1.401826e+10  \n",
            "54  3.240790e+07  1.561124e+08  7.520104e+08  3.622516e+09  1.745005e+10  \n",
            "55  3.796552e+07  1.855345e+08  9.066928e+08  4.430937e+09  2.165364e+10  \n",
            "56  4.437647e+07  2.199624e+08  1.090295e+09  5.404306e+09  2.678771e+10  \n",
            "57  5.175692e+07  2.601586e+08  1.307700e+09  6.573217e+09  3.304059e+10  \n",
            "58  6.023687e+07  3.069889e+08  1.564526e+09  7.973391e+09  4.063528e+10  \n",
            "59  6.996162e+07  3.614339e+08  1.867231e+09  9.646441e+09  4.983520e+10  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "x = np.array([i*np.pi/180 for i in range(60,300,4)])\n",
        "\n",
        "np.random.seed(10) #Setting seed for reproducibility\n",
        "\n",
        "y = np.sin(x) + np.random.normal(0,0.15,len(x))\n",
        "\n",
        "df= pd.DataFrame(np.column_stack([x,y]),columns=['x','y'])\n",
        "\n",
        "for i in range(2,16): #power of 1 is already there\n",
        " colname = 'x_%d'%i #new var will be x_power\n",
        " df[colname] = df['x']**i\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(['y'],axis=1)\n",
        "\n",
        "Y=df.iloc[:,1]\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler=StandardScaler()\n",
        "\n",
        "X_scaled=scaler.fit_transform(X)\n",
        "\n",
        "X_scaled=np.insert(X_scaled,0,values=1,axis=1)"
      ],
      "metadata": {
        "id": "M5o6wdUUIBvM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "KzbNYnsYIeMK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lamba=0.001\n",
        "\n",
        "A=X_train.T.dot(X_train)\n",
        "I=np.identity(len(A),dtype='int')\n",
        "B=A+lamba*I\n",
        "\n",
        "C=np.linalg.inv(B)\n",
        "\n",
        "D=C.dot(X_train.T)\n",
        "\n",
        "beta=D.dot(Y_train)"
      ],
      "metadata": {
        "id": "vKUss3TsIiae"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_predict=X_test.dot(beta)\n",
        "\n",
        "print(Y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noA2yi33I-LZ",
        "outputId": "d4e8a5e3-30b1-442b-e912-5fc47f1d48b7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.91886872  0.98089512 -0.37858576 -0.91792187  0.91412707 -0.85423698\n",
            " -0.14821958 -0.97220769  0.93402742 -0.82549473 -0.94551187 -0.96007629\n",
            "  0.00343604  0.96535837 -0.91475809  0.80080899  0.98037703  0.98392925]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error=Y_test-Y_predict\n",
        "\n",
        "square_error=np.power(error,2)\n",
        "\n",
        "sum_square_error=np.sum(square_error)\n",
        "\n",
        "mean_square_error=sum_square_error/len(Y_predict)\n",
        "\n",
        "print(mean_square_error)\n",
        "\n",
        "rms_error=np.sqrt(mean_square_error)\n",
        "\n",
        "print(rms_error)\n",
        "\n",
        "y_mean=np.mean(Y_test)\n",
        "\n",
        "total_variance=np.sum((Y_test-y_mean)**2)\n",
        "\n",
        "print(1-sum_square_error/total_variance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzLPwhA5JEze",
        "outputId": "2f03a86d-7797-4957-9b31-fe4f49257998"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.009032448090750001\n",
            "0.09503919239319114\n",
            "0.9880291811035271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_ridge = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]\n",
        "import matplotlib as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "R2_score=[]\n",
        "\n",
        "for i in range(len(lambda_ridge)):\n",
        "\n",
        "  A=X_train.T.dot(X_train)\n",
        "\n",
        "  B=A+lambda_ridge[i]*I\n",
        "\n",
        "  C=np.linalg.inv(B)\n",
        "\n",
        "  D=C.dot(X_train.T)\n",
        "\n",
        "  beta=D.dot(Y_train)\n",
        "\n",
        "  Y_predict=X_test.dot(beta)\n",
        "\n",
        "  R2_score.append((metrics.r2_score(Y_test,Y_predict)))\n",
        "\n",
        "  \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(lambda_ridge,R2_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "pEHhtlRpJQae",
        "outputId": "5528235c-f887-4b07-d4a8-9c70bda1171b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa5c3604d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "ridge=Ridge(alpha=0.001, normalize=True)\n",
        "\n",
        "model=ridge.fit(X_train,Y_train)\n",
        "\n",
        "Y_predict=model.predict(X_test)\n",
        "\n",
        "print(metrics.r2_score(Y_test,Y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6gffpo8JqQH",
        "outputId": "5e36f74a-8f65-434c-e51a-a6e2c712e7f3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9889244857152456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * n_samples. \n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "lasso=Lasso(alpha=0.001, normalize=True)\n",
        "\n",
        "model=lasso.fit(X_train,Y_train)\n",
        "\n",
        "Y_predict=model.predict(X_test)\n",
        "\n",
        "print(metrics.r2_score(Y_test,Y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsByECGaJ6T8",
        "outputId": "2db8faea-e057-425d-a4b1-335739553509"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9780622256563285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vkcfXW-pJ8Ez"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}